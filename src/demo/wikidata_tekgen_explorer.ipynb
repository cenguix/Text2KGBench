{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ontology(ont_path):\n",
    "    with open(ont_path) as in_file: \n",
    "        data = json.load(in_file)\n",
    "        print(f\"Ontology: {data['title']}\")\n",
    "        cls_str = \"\\n\\t\".join([f\"{c['label']} ({c['qid']})\"  for c in data['concepts']])\n",
    "        rel_str = \"\\n\\t\".join([f\"{c['label']} ({c['pid']})\"  for c in data['relations']])\n",
    "        print(f\"Concepts:\\n\\t{cls_str}\")\n",
    "        print(f\"Relations:\\n\\t{rel_str}\")   \n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    content = list()\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            content.append(json.loads(line))\n",
    "    return content\n",
    "\n",
    "def load_valid_ids(dir_path):\n",
    "    all_lines = []\n",
    "    jsonl_files = glob.glob(dir_path + '/*.txt')\n",
    "    for file_path in sorted(jsonl_files):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = [line.strip() for line in file.readlines()]\n",
    "            all_lines.append(lines)\n",
    "    return all_lines\n",
    "        \n",
    "def load_all_jsonl(dir_path):\n",
    "    jsonl_files = glob.glob(dir_path + '/*.jsonl')\n",
    "    content = list()\n",
    "    for file_path in jsonl_files:\n",
    "        content += load_jsonl(file_path)\n",
    "    return content\n",
    "\n",
    "def load_test_data(test_path_prefix):\n",
    "    test_data = load_all_jsonl(test_path_prefix)\n",
    "    test_data = {td[\"id\"]:td for td in test_data}\n",
    "    return test_data\n",
    "\n",
    "def load_prompts(prompt_path_prefix):\n",
    "    prompts = load_all_jsonl(prompt_path_prefix)\n",
    "    prompts = {p[\"id\"]:p for p in prompts}\n",
    "    return prompts\n",
    "\n",
    "def load_llm_ouputs(llm_output_prefix):\n",
    "    llm_ouputs = load_all_jsonl(llm_output_prefix)\n",
    "    llm_ouputs = {p[\"id\"]:p for p in llm_ouputs}\n",
    "    return llm_ouputs\n",
    "\n",
    "def print_llm_output(llm_output):\n",
    "    print(f\"Test ID: {llm_output['id']}\\n\")\n",
    "    print(f\"LLM Response:\\n\\n{llm_output['response']}\\n\")\n",
    "    print(f\"Triples:\")\n",
    "    for tr in llm_output['triples']:\n",
    "        print(f\"\\t{tr}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ont_path_prefix = \"../../data/wikidata_tekgen/ontologies/\"\n",
    "ontologies = [\n",
    "    \"1_movie_ontology.json\",\n",
    "    \"2_music_ontology.json\",\n",
    "    \"3_sport_ontology.json\",\n",
    "    \"4_book_ontology.json\",\n",
    "    \"5_military_ontology.json\",\n",
    "    \"6_computer_ontology.json\",\n",
    "    \"7_space_ontology.json\",\n",
    "    \"8_politics_ontology.json\",\n",
    "    \"9_nature_ontology.json\",\n",
    "    \"10_culture_ontology.json\"\n",
    "]\n",
    "ontologies = [ont_path_prefix + ont for ont in ontologies]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ontology content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontology: Music Ontology\n",
      "Concepts:\n",
      "\thuman (Q5)\n",
      "\tmusic (Q638)\n",
      "\tmusical work (Q2188189)\n",
      "\trecord producer (Q4830453)\n",
      "\tcomposed musical work (Q207628)\n",
      "\tcomposer (Q36834)\n",
      "\tlanguage (Q34770)\n",
      "\tmusic genre (Q188451)\n",
      "\tvoice (Q7390)\n",
      "\tmusicology (Q164204)\n",
      "\tmusic industry (Q746359)\n",
      "\talbum (Q482994)\n",
      "\taward  (Q618779)\n",
      "Relations:\n",
      "\tcomposer (P86)\n",
      "\tpart of (P361)\n",
      "\tlyrics by (P676)\n",
      "\tpublication date (P577)\n",
      "\tlanguage of work or name (P407)\n",
      "\tvoice type (P412)\n",
      "\tinstrumentation (P870)\n",
      "\ttracklist (P658)\n",
      "\tgenre (P136)\n",
      "\tperformer (P175)\n",
      "\tproducer (P162)\n",
      "\tnominated for (P1411)\n",
      "\trecord label (P264)\n"
     ]
    }
   ],
   "source": [
    "show_ontology(ontologies[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path_prefix = \"../../data/wikidata_tekgen/test/\"\n",
    "test_data = load_test_data(test_path_prefix)\n",
    "\n",
    "valid_ids_prefix = \"../../data/wikidata_tekgen/manually_verified_sentences/\"\n",
    "valid_ids = load_valid_ids(valid_ids_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'ont_5_military_test_7',\n",
       " 'sent': 'Felix von Bendemann (8 August 1848Â\\xa0- 31 October 1915) was an Admiral of the German Imperial Navy (Kaiserliche Marine).'}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [2][10]  [3][1]  [4][6] [5][3]\n",
    "\n",
    "test_id = valid_ids[5][3]\n",
    "test_data[test_id]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_path_prefix = \"../../data/wikidata_tekgen/baselines/prompts/\"\n",
    "prompts = load_prompts(prompt_path_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ID: ont_5_military_test_7\n",
      "Prompt: \n",
      "Given the following ontology and sentences, please extract the triples from the sentence according to the relations in the ontology. In the output, only include the triples in the given output format.\n",
      "CONTEXT:\n",
      "Ontology Concepts: rank, military rank, military vehicle, military unit, human, country, military casualty classification, armed organization, command, military museum, organization, military personnel, military equipment,\n",
      "Ontology Relations: military_rank(human,military rank), military_branch(human,military unit), military_casualty_classification_(human,military casualty classification), designed_by(military equipment,organization), designed_by(military vehicle,organization), commanded_by(command,human), next_higher_rank(military rank,rank), designated_as_terrorist_by(armed organization,country), wing_configuration(,)\n",
      "\n",
      "Example Sentence: Alfred Meyer-Waldeck (27 November 1864 - 25 August 1928) was a vice admiral in the Imperial German Navy from 1909 to 1914.\n",
      "Example Output: military_rank(Alfred Meyer-Waldeck,admiral)\n",
      "\n",
      "Test Sentence: Felix von Bendemann (8 August 1848Â - 31 October 1915) was an Admiral of the German Imperial Navy (Kaiserliche Marine).\n",
      "Test Output: \n"
     ]
    }
   ],
   "source": [
    "test_prompt = prompts[test_id]\n",
    "print(f\"Test ID: {test_prompt['id']}\")\n",
    "print(f\"Prompt: {test_prompt['prompt']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLL Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "vicuna_output_prefix =  \"../../data/wikidata_tekgen/baselines/Vicuna-13B/llm_responses/\"\n",
    "vicuna_outputs = load_llm_ouputs(vicuna_output_prefix)\n",
    "\n",
    "alpaca_lora_output_prefix =  \"../../data/wikidata_tekgen/baselines/Alpaca-LoRA-13B/llm_responses/\"\n",
    "alpaca_lora_outputs = load_llm_ouputs(alpaca_lora_output_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vicuna-13B\n",
      "Test ID: ont_5_military_test_7\n",
      "\n",
      "LLM Response:\n",
      "\n",
      "military\\_rank(Felix von Bendemann,admiral)\n",
      "military\\_unit(Imperial German Navy,Felix von Bendemann)\n",
      "\n",
      "Note: The test output is empty because the triple format specified in the prompt does not include the object of the relation (i.e., the person or entity that the relation applies to). To include the object of the relation in the output, the format should be: subject, object, relation. For example: \"Felix von Bendemann, Imperial German Navy, military\\_rank(admiral)\"\n",
      "\n",
      "Triples:\n",
      "\t['Felix von Bendemann', 'military_rank', 'admiral']\n",
      "\t['Imperial German Navy', 'military_unit', 'Felix von Bendemann']\n"
     ]
    }
   ],
   "source": [
    "print(\"Vicuna-13B\")\n",
    "print_llm_output(vicuna_outputs[test_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpaca-LoRA-13B\n",
      "Test ID: ont_5_military_test_7\n",
      "\n",
      "LLM Response:\n",
      "\n",
      "Felix von Bendemann (8 August 1848Â - 31 October 1915) was an Admiral of the German Imperial Navy (Kaiserliche Marine).\n",
      "military_rank(Felix von Bendemann,admiral)\n",
      "military_unit(Felix von Bendemann,Kaiserliche Marine)\n",
      "\n",
      "Triples:\n",
      "\t['Felix von Bendemann', 'military_rank', 'admiral']\n",
      "\t['Felix von Bendemann', 'military_unit', 'Kaiserliche Marine']\n"
     ]
    }
   ],
   "source": [
    "print(\"Alpaca-LoRA-13B\")\n",
    "print_llm_output(alpaca_lora_outputs[test_id])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgc2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
